{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1481dc74-3973-44cd-aa91-d85da73bb491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    spark.conf.get(\"spark.databricks.clusterUsageTags.clusterUnityCatalogMode\")\n",
    "    != \"USER_ISOLATION\"\n",
    "):\n",
    "    print(\"Dette er ikke et felles cluster!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb0dcca2-6df2-4b48-9058-b78d7e8cd65b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Users/fabian.heflo@kartverket.no/Snuplasser/src/dataProcessing/transform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c519bfc0-b61c-41fb-bfa0-3b67d55fd2c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from dataProcessing.dataset import SnuplassDataset, load_numpy_split_stack\n",
    "from model.unet import UNet\n",
    "from dataProcessing.augmentation_config import augmentation_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae238a72-eaf8-40ec-b91e-b66af840161c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    mlflow.pytorch.autolog()  # Lagrer modellen under Experiments. Kan hente modellen med model = mlflow.pytorch.load_model(\"runs:/<run_id>/model\")\n",
    "\n",
    "    cfg = augmentation_profiles[\"default\"]\n",
    "    batch_size = 8\n",
    "    num_epochs = 1\n",
    "    learning_rate = 1e-3\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_ids, val_ids, _ = load_numpy_split_stack(\n",
    "        image_dir=\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/img/\",\n",
    "        mask_dir=\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/lab/\",\n",
    "        dom_dir=\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/dom/\",\n",
    "    )\n",
    "\n",
    "    train_dataset = SnuplassDataset(\n",
    "        image_dir=\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/img/\",\n",
    "        mask_dir=\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/lab/\",\n",
    "        dom_dir=\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/dom/\",\n",
    "        file_list=train_ids,\n",
    "        transform=get_train_transforms(cfg, ratio=None),  # ratio=None for baseline\n",
    "        # For å bruke augmentering, sett ratio til en verdi mellom 0 og 1\n",
    "    )\n",
    "\n",
    "    val_dataset = SnuplassDataset(\n",
    "        image_dir=\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/img/\",\n",
    "        mask_dir=\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/lab/\",\n",
    "        dom_dir=\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/dom/\",\n",
    "        file_list=val_ids,\n",
    "        transform=get_val_transforms(),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = UNet(n_channels=4, n_classes=1, bilinear=False).to(\n",
    "        device\n",
    "    )  # bare å bytte modell\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    with mlflow.start_run(run_name=\"UNet_baseline_4ch\"):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Trening\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for images, masks in tqdm(\n",
    "                train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"\n",
    "            ):\n",
    "                images, masks = images.to(device).float(), masks.to(device).float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = total_loss / len(train_loader)\n",
    "            print(f\"\\nTrain loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "            # Validering\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, masks in tqdm(\n",
    "                    val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"\n",
    "                ):\n",
    "                    images, masks = images.to(device).float(), masks.to(device).float()\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs.squeeze(1), masks)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"Val loss: {avg_val_loss:.4f}\")\n",
    "        # writer.close()\n",
    "\n",
    "    print(\"✅ Trening ferdig\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
