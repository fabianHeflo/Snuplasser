{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d59cf6d-a1f2-4b41-b4b9-0064b5e7bfbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39029f9d-d922-4eeb-8466-1c93ecbd3892",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import json\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35e750f2-7651-4c80-b011-db12e6319bb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SnuplassDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, dom_dir, file_list, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.dom_dir = dom_dir\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_id = self.file_list[idx]\n",
    "        image_path = os.path.join(self.image_dir, f\"{file_id}.png\")\n",
    "        mask_path = os.path.join(self.mask_dir, f\"mask_{file_id[6:]}.png\")\n",
    "        dom_path = os.path.join(self.dom_dir, f\"dom_{file_id[6:]}.png\")\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        dom = Image.open(dom_path).convert(\"L\")\n",
    "\n",
    "        dom = np.expand_dims(dom, axis=-1)  # (H, W, 1)\n",
    "        image = np.concatenate((image, dom), axis=-1)  # (H, W, 4)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(\n",
    "                image=np.array(image),\n",
    "                mask=np.array(mask) // 255,\n",
    "            )\n",
    "            image = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "\n",
    "        if not isinstance(image, torch.Tensor):\n",
    "            image = torch.from_numpy(np.array(image)).permute(2, 0, 1)\n",
    "\n",
    "        if not isinstance(mask, torch.Tensor):\n",
    "            mask = torch.from_numpy(np.array(mask) / 255).unsqueeze(0).float()\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a92a13b4-ca5f-436f-bec0-e065da196256",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_numpy_split_stack(\n",
    "    image_dir, mask_dir, dom_dir, holdout_size=5, test_size=0.2, seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Laster inn hele datasettet som numpy-arrays, splitter i tren/val/test og returnerer stacks.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    all_files = sorted(\n",
    "        [\n",
    "            f\n",
    "            for f in os.listdir(image_dir)\n",
    "            if f.startswith(\"image_\") and f.endswith(\".png\")\n",
    "        ]\n",
    "    )\n",
    "    file_ids = [Path(f).stem for f in all_files]\n",
    "\n",
    "    if len(file_ids) < holdout_size + 2:\n",
    "        raise ValueError(\n",
    "            \"For få bilder til å gjennomføre splitting med holdout og validering.\"\n",
    "        )\n",
    "\n",
    "    np.random.shuffle(file_ids)\n",
    "    holdout_ids = file_ids[:holdout_size]\n",
    "    remaining_ids = file_ids[holdout_size:]\n",
    "\n",
    "    train_ids, val_ids = train_test_split(\n",
    "        remaining_ids, test_size=test_size, random_state=seed\n",
    "    )\n",
    "\n",
    "    return train_ids, val_ids, holdout_ids"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dataset",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
